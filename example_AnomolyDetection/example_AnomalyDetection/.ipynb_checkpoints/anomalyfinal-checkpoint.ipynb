{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Anomaly Detection in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Anomaly detection is a technique used to identify unusual patterns that do not conform to expected behavior, called outliers. It has many applications in business, from intrusion detection (identifying strange patterns in network traffic that could signal a hack) to system health monitoring (spotting a malignant tumor in an MRI scan), and from fraud detection in credit card transactions to fault detection in operating environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this article we will implement the anomaly detection algorithm and apply it to detect failing servers on a network.\n",
    "Before going into the original dataset let's first visualize how to proceed and carry out different functions. Let's start by importing few libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import math\n",
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We'll be using a dummy dataset to check whether all the functions are working properly and we would then use these functions on our original dataset. Let's import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset = sio.loadmat('anomalyData.mat')\n",
    "X = dataset['X']\n",
    "Xval = dataset['Xval']\n",
    "yval = dataset['yval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "sio.loadmat() loads our dataset('anomalyData.mat') into the variable dataset. The variable 'X' contains the training dataset, 'Xval' the cross validation set and 'yval' the corresponding output for the 'Xval'. Let's see the array 'X' that we are going to use to fit it in a Gaussian model to detect anomalous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307L, 2L)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As you can see there are 307 training examples and each having 2 features. The features measure the throughput (mb/s) and latency (ms) of response of each server. While your servers were operating, you collected m = 307 examples of how they were behaving,and thus have an unlabeled dataset {x(1), . . . , x(m)}. You suspect that the vast majority of these examples are “normal” (non-anomalous) examples of the servers operating normally, but there might also be some examples of servers acting anomalously within this dataset. Now, let's visualize the dataset to have a clear picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7e1e470>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], marker = \"x\")\n",
    "plt.xlabel('Latency(ms)')\n",
    "plt.ylabel('Throughput(mb/s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gaussian distribution\n",
    "To perform anomaly detection, you will first need to fit a model to the data’s distribution.\n",
    "Given a training set {x(1), ..., x(m)} (where x(i) ∈ R^n, here n = 2), you want to estimate the Gaussian distribution for each of the features. For each feature (i = 1 . . . n), you need to find parameters mean and variance(mu, sigma^2). For doing that let's write down the function that calculates the mean and variance of the array(or you can call it matrix) X.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def estimateGaussian(X):\n",
    "    n = np.size(X, 1)\n",
    "    m = np.size(X, 0)\n",
    "    mu = np.zeros((n, 1))\n",
    "    sigma2 = np.zeros((n, 1))\n",
    "    \n",
    "    mu = np.reshape((1/m)*np.sum(X, 0), (1, n))\n",
    "    sigma2 = np.reshape((1/m)*np.sum(np.power((X - mu),2), 0),(1, n))\n",
    "    \n",
    "    return mu, sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mu, sigma2 = estimateGaussian(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean: ', array([[ 0.,  0.]]), ' variance: ', array([[ 0.,  0.]]))\n"
     ]
    }
   ],
   "source": [
    "print('mean: ',mu,' variance: ',sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have the mean and variance let's find out the probabilities of the dataset by writing down the multivariate Gaussian function. But before that let's look at what actually the function does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multivariate Gaussian Distribution\n",
    "The multivariate gaussian is used to find the probabilities of each training example. It takes the mean(mu) and the co-variance matrix as it's parameters and returns the probabilities of the dataset passed. Let's see how to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-e98e8392e081>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-e98e8392e081>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    val = np.reshape((-0.5)*np.sum(np.multiply((X@inv),X), 1),(np.size(X, 0), 1))\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def multivariateGaussian(X, mu, sigma2):\n",
    "     n = np.size(sigma2, 1)\n",
    "     m = np.size(sigma2, 0)\n",
    "     #print(m,n)\n",
    "     \n",
    "     if n == 1 or m == 1:        \n",
    "         sigma2 = np.diag(sigma2[0, :])\n",
    "     \n",
    "     X = X - mu\n",
    "     pi = math.pi\n",
    "     det = np.linalg.det(sigma2)\n",
    "     inv = np.linalg.inv(sigma2)\n",
    "     val = np.reshape((-0.5)*np.sum(np.multiply((X@inv),X), 1),(np.size(X, 0), 1))\n",
    "     \n",
    "     p = np.power(2*pi, -n/2)*np.power(det, -0.5)*np.exp(val)\n",
    "     \n",
    "     return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Inside the function first we convert the sigma2 vector into a covarince matrix and then we simply apply the formula for the multivariate distribution to get the probability vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p = multivariateGaussian(X, mu, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "p contains the proobabilities of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(p.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In an anomaly detection we use a threshold(epsilon) value of probability to determine whether an example is anomalous or not.\n",
    "\n",
    "P > epsilon (negative or normal case),\n",
    "P < epsilon (positive or anomalous case)\n",
    "\n",
    "To determine this threshold value epsilon we need a cross-validation set which we already have collected from our anomalyFile above. Let's see how we go about doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pval = multivariateGaussian(Xval, mu, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "pval contains the probabilities for the cross-validation vector that we are gonna use to calculate threshold. Now, we are going to use this pval vector to calculate the threshold value. Precisely, we need a function that can analyze some labeled datasets and give us the threshold on the basis of some underlying theory. Let's see this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def selectThreshHold(yval, pval):\n",
    "    \n",
    "    F1 = 0\n",
    "    bestF1 = 0\n",
    "    bestEpsilon = 0\n",
    "    \n",
    "    stepsize = (np.max(pval) - np.min(pval))/1000\n",
    "        \n",
    "    epsVec = np.arange(np.min(pval), np.max(pval), stepsize)\n",
    "    noe = len(epsVec)\n",
    "    \n",
    "    for eps in range(noe):\n",
    "        epsilon = epsVec[eps]\n",
    "        pred = (pval < epsilon)\n",
    "        prec, rec = 0,0\n",
    "        tp,fp,fn = 0,0,0\n",
    "        \n",
    "        try:\n",
    "            for i in range(np.size(pval,0)):\n",
    "                if pred[i] == 1 and yval[i] == 1:\n",
    "                    tp+=1\n",
    "                elif pred[i] == 1 and yval[i] == 0:\n",
    "                    fp+=1\n",
    "                elif pred[i] == 0 and yval[i] == 1:\n",
    "                    fn+=1\n",
    "            prec = tp/(tp + fp)\n",
    "            rec = tp/(tp + fn)\n",
    "            F1 = 2*prec*rec/(prec + rec)\n",
    "            if F1 > bestF1:\n",
    "                bestF1 = F1\n",
    "                bestEpsilon = epsilon\n",
    "        except ZeroDivisionError:\n",
    "            print('Warning dividing by zero!!')          \n",
    "       \n",
    "    return bestF1, bestEpsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We'll implement F1-score principle to determine the best epsilon value. First, we use a variable called stepsize that takes a number of different epsilon values right from the minimum probability in pval to it's maximum. Then, we loop over all such values to find the optimum precision and recall. We are going to need a try except block because there can be cases where we divide by zero to calculate precision and recall. The epsilon value that gives the highest F1-score is taken as the best epsilon. The function returns the bestF1 and bestEpsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "F1, epsilon = selectThreshHold(yval, pval)\n",
    "print('Epsilon and F1 are:',epsilon, F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To find out the outliers we need to check the examples whose probabilties are less than the threshold value epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outl = (p < epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to return the indices of the outliers to identify the faulty servers. This gives us a vector with binary entries where 1 means anomaly and 0 means normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def findIndices(binVec):\n",
    "    l = []\n",
    "    for i in range(len(binVec)):\n",
    "        if binVec[i] == 1:\n",
    "            l.append(i)\n",
    "    return l\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "listOfOutliers = findIndices(outl)\n",
    "count_outliers = len(listOfOutliers)\n",
    "print('\\n\\nNumber of outliers:', count_outliers)\n",
    "print('\\n',listOfOutliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Thus, we have detected the faulty servers. One last thing in this dummy dataset is to visualize the anomalies graphically. Let's see how to plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], marker = \"x\")\n",
    "plt.xlabel('Latency(ms)')\n",
    "plt.ylabel('Throughput(mb/s)')\n",
    "plt.scatter(X[listOfOutliers,0], X[listOfOutliers, 1], facecolors = 'none', edgecolors = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The red circles shows the faulty servers in the network. Congratulations! you've successfully written down the code to work on some original and pretty large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, let's work this code out in some larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "newDataset = sio.loadmat('anomalyDataTest.mat')\n",
    "\n",
    "Xtest = newDataset['X']\n",
    "Xvaltest = newDataset['Xval']\n",
    "yvaltest = newDataset['yval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(Xtest.shape)\n",
    "print(Xvaltest.shape)\n",
    "print(yvaltest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We'll repeat the same steps as above but simply on a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mutest, sigma2test = estimateGaussian(Xtest)\n",
    "\n",
    "ptest = multivariateGaussian(Xtest, mutest, sigma2test)\n",
    "\n",
    "pvaltest = multivariateGaussian(Xvaltest, mutest, sigma2test)\n",
    "\n",
    "\n",
    "F1test, epsilontest = selectThreshHold(yvaltest, pvaltest)\n",
    "print('\\nBest epsilon and F1 are\\n',epsilontest, F1test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we just need to check for the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outliersTest = ptest < epsilontest\n",
    "listOfOl = findIndices(outliersTest)\n",
    "\n",
    "print('\\n\\n Outliers are:\\n',listOfOl)\n",
    "print('\\n\\nNumber of outliers are: ',len(listOfOl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
